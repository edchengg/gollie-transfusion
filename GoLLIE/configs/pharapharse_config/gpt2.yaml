#Training args
model_name_or_path: EleutherAI/gpt-neo-125m
config_template: vicuna_v1.1
torch_dtype: "auto"
use_lora: false
quantization: null
predict_with_generate: true
do_predict: true
per_device_eval_batch_size: 4

generation_args_json: /home/ikergarcia/Documents/CoLLIE/configs/pharapharse_config/generation_config.json
output_dir: /home/ikergarcia/Documents/CoLLIE/paraphrase/vicuna-13b


# dataset arguments
datasets:
  - ace05
  - rams
  - conll03
  - casie
  - tacred
  - ontonotes5
  - ncbidisease
  - bc5cdr
  - diann
  - wnut17
  - multinerd
  - wikievents
  - fabner
  - e3c
  - broadtwitter
  - harveyner
  - mitmovie
  - mitrestaurant
  - crossner
language: en





# reporting
logging_strategy: steps
logging_first_step: true
logging_steps: 25
report_to: none


# hub settings
push_to_hub: false
resume_from_checkpoint: false

# performance
bf16: false
fp16: false
torch_compile: false
ddp_find_unused_parameters: false